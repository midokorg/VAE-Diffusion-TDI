Diffusion-VAE â€” Reconstruction TDI (PyTorch)

Ce dÃ©pÃ´t contient un pipeline PyTorch pour entraÃ®ner un ConvVAE sur des images TDI (Tissue Doppler Imaging) en niveau de gris (1 canal), avec Ã©valuation via MSE et SSIM, et visualisation des reconstructions. Le code est pensÃ© pour Google Colab + Google Drive, mais peut Ãªtre exÃ©cutÃ© localement avec de lÃ©gÃ¨res modifications.

âœ¨ FonctionnalitÃ©s

Chargement dâ€™images TDI 1-canal, normalisÃ©es et redimensionnÃ©es.

ConvVAE avec skip-connections cÃ´tÃ© dÃ©codeur.

Pertes : MSE, 1â€“SSIM, KL (pondÃ©rÃ©es).

Journalisation des pertes/metrics, sauvegarde modÃ¨le et figures.

ReproductibilitÃ© (graine fixÃ©e).

Splitting train/val (90/10 par dÃ©faut).

âš ï¸ Le script actuel se concentre sur la reconstruction. Lâ€™augmentation par modÃ¨les de diffusion nâ€™est pas incluse dans ce fichier (ici : VAE seul).

ğŸ“ Structure attendue des donnÃ©es
DATATDI/
â”œâ”€â”€ CTRCD/
â”‚   â”œâ”€â”€ patient001.png
â”‚   â”œâ”€â”€ ...
â””â”€â”€ NO_CTRCD/
    â”œâ”€â”€ patient101.png
    â”œâ”€â”€ ...


Les fichiers .png sont dÃ©tectÃ©s automatiquement. Les sous-dossiers CTRCD et NO_CTRCD sont obligatoires (mÃªme si seule la reconstruction est utilisÃ©e, cela uniformise lâ€™accÃ¨s aux images).

ğŸ§° PrÃ©requis

Python 3.9+

PyTorch (CUDA si dispo)

torchvision

numpy, pandas, pillow (PIL)

matplotlib

tqdm

pytorch-msssim

(Colab) montÃ© sur Google Drive

Installation rapide (exemple) :

pip install torch torchvision pytorch-msssim tqdm pillow matplotlib pandas

âš™ï¸ Variables Ã  dÃ©finir (IMPORTANT)

Le script utilise des constantes non dÃ©finies dans le snippet. Ajoute-les avant de crÃ©er le dataset :

# HyperparamÃ¨tres / chemins
IMAGE_SIZE   = (160, 384)   # (H, W) final des trames
BATCH_SIZE   = 16
LATENT_DIM   = 256
LR           = 1e-3
EPOCHS       = 50
ALPHA_SSIM   = 1.0          # poids pour (1-SSIM)
BETA_KL      = 1e-4         # poids KL
OUT_DIR      = os.path.join(BASE_DIR, 'outputs_vae')

os.makedirs(OUT_DIR, exist_ok=True)


ğŸ’¡ Tu peux ajuster BATCH_SIZE selon ta VRAM.
ğŸ’¡ IMAGE_SIZE doit Ãªtre compatible avec 4 couches de Conv2d stride=2 (divisible par 16).

ğŸš€ Utilisation (Colab)

Monte Google Drive (dÃ©jÃ  dans le code) :

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
BASE_DIR  = '/content/drive/MyDrive/colab'
DATA_DIR  = os.path.join(BASE_DIR, 'DATATDI')


DÃ©finis les variables manquantes (cf. section prÃ©cÃ©dente).

Lance lâ€™entraÃ®nement. Les sorties sont dans OUT_DIR :

vae_tdi.pt

train_loss.png, val_metrics.png

reconstructions.png

ğŸ§© DÃ©tails techniques
Dataset
class TDIDataset(Dataset):
    def __init__(self, root, size):
        self.files = []
        for sub in ['CTRCD','NO_CTRCD']:
            d = os.path.join(root, sub)
            for f in os.listdir(d):
                if f.lower().endswith('.png'):
                    self.files.append(os.path.join(d,f))
        self.tf = T.Compose([
            T.Grayscale(1),        # 1 canal
            T.Resize(size),        # (H, W)
            T.ToTensor(),          # [0,1]
            T.Normalize([0.5],[0.5])  # [-1,1]
        ])
    def __len__(self): return len(self.files)
    def __getitem__(self, i):
        img = Image.open(self.files[i]).convert('RGB')
        return self.tf(img), self.files[i]

ModÃ¨le (ConvVAE + skips)

Encodeur : 4 blocs Conv2d (1â†’32â†’64â†’128â†’256), stride=2.

Bottleneck : fc_mu, fc_logvar, reparamÃ©trisation.

DÃ©codeur : 4 blocs ConvTranspose2d (256â†’128â†’64â†’32â†’1) + skip-connections (+ e3, e2, e1).

Sortie avec Tanh â†’ plage [-1, 1].

Pertes
mse_fn  = nn.MSELoss()
ssim_fn = SSIM(data_range=2.0, channel=1, win_size=7)  # data_range=2 pour [-1,1]
loss = l_mse + ALPHA_SSIM * (1 - ssim) + BETA_KL * kld

ğŸ§ª Validation & courbes

val_mses : MSE moyen par epoch (validation).

val_ssims : SSIM moyen par epoch (validation).

Figures :

train_loss.png

val_metrics.png (MSE, SSIM)

ğŸ’¾ Sauvegardes

Le script sauvegarde :

vae_tdi.pt (poids du VAE).

âš ï¸ Le snippet montre aussi :

joblib.dump(dataset.scaler,   os.path.join(OUT_DIR, 'scaler.joblib'))
joblib.dump(dataset.encoders, os.path.join(OUT_DIR, 'encoders.joblib'))


Ces objets nâ€™existent pas dans ce fichier (pas de variables cliniques ici).
â¡ï¸ Supprime ces lignes ou fournis un dataset tabulaire avec scaler/encoders.

ğŸ–¼ï¸ Inspection qualitative

Le bloc actuel contient une petite erreur (utilise x sans le charger). Remplace par :

vae.eval()
fig, axs = plt.subplots(5,2,figsize=(6,15))
with torch.no_grad():
    # prends un batch de la validation
    for i, (x, _) in enumerate(va_loader):
        x = x.to(DEVICE)
        recon, _, _ = vae(x)
        # on n'affiche que les 5 premiÃ¨res images du batch
        for k in range(min(5, x.size(0))):
            orig = (x[k]*0.5 + 0.5).clamp(0,1)
            rec  = (recon[k]*0.5 + 0.5).clamp(0,1)
            axs[k,0].imshow(orig[0].cpu(), cmap='gray'); axs[k,0].set_title("Original"); axs[k,0].axis('off')
            axs[k,1].imshow(rec[0].cpu(),  cmap='gray'); axs[k,1].set_title("Reconstr."); axs[k,1].axis('off')
        break  # une itÃ©ration suffit
plt.tight_layout()
plt.savefig(os.path.join(OUT_DIR,"reconstructions.png"))
plt.show()

ğŸ”§ ExÃ©cution locale (sans Colab)

Remplace la partie Drive par des chemins locaux :

BASE_DIR = '/chemin/vers/ton/projet'
DATA_DIR = os.path.join(BASE_DIR, 'DATATDI')


Assure-toi que CUDA est disponible sinon lâ€™entraÃ®nement passera en CPU.

ğŸ§¯ DÃ©pannage (FAQ)

NameError: IMAGE_SIZE is not defined
âœ DÃ©finis toutes les constantes (cf. section Variables Ã  dÃ©finir).

joblib is not defined
âœ pip install joblib et import joblib, et assure-toi dâ€™avoir des objets scaler/encoders (sinon supprime ces lignes).

Erreur SSIM / tailles
âœ win_size=7 exige des images â‰¥ 7Ã—7. Ton IMAGE_SIZE est 160Ã—384 â†’ OK.

Artifacts visuels / reconstructions floues
âœ Essaie dâ€™augmenter LATENT_DIM, baisse BETA_KL, ou entraÃ®ne plus longtemps.

MÃ©moire saturÃ©e (CUDA OOM)
âœ RÃ©duis BATCH_SIZE, ou lâ€™IMAGE_SIZE.

ğŸ“Š Feuille de route (TODO)

 Factoriser la config via YAML/argparse.

 Ajouter k-fold CV et moyennes Â± Ã©cart-type.

 Logger (TensorBoard/W&B).

 Export ONNX / TorchScript.

 Dataset 2D/3D avec lecture DICOM.

 Module Diffusion pour augmentation.

ğŸ”’ DonnÃ©es sensibles

Ne pousse aucune donnÃ©e patient ni mÃ©tadonnÃ©e identifiante. Conserve uniquement des donnÃ©es anonymisÃ©es ou synthÃ©tiques.

ğŸ“œ Licence

Ajoute un fichier LICENSE (ex. MIT, Apache-2.0). Exemple MIT :

MIT License â€” Copyright (c) 2025 â€¦

ğŸ“£ Citation

Si tu utilises ce code dans une publication :

@software{DiffusionVAE_TDI_2025,
  author = {Ton Nom},
  title = {Diffusion-VAE for TDI Reconstruction},
  year = {2025},
  url = {https://github.com/<ton-user>/<ton-repo>}
}

ğŸ¤ Contributions

Issues et PR bienvenues ! Merci de respecter PEP8 et dâ€™ajouter des tests simples (chargement dataset, passage avant/arriÃ¨re du modÃ¨le).

ğŸ“ Contact

Auteur : Ton Nom

Email : ton.email@exemple.com

Institution : â€¦
